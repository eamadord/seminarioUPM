{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3-TrainUseWE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNiiBOhkNlVVMrGdmGkLnWe",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isegura/seminarioUPM/blob/main/3_TrainUseWE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_LPLzLoD5lw"
      },
      "source": [
        "# How to train a word Embedding models in Python with Gensim\n",
        "\n",
        "https://machinelearningmastery.com/develop-word-embeddings-python-gensim/\n",
        "\n",
        "In this notebook, we will learn how to train a word embedding model. To do this, we will use the library Gensim. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neA-Mq4gJyIV"
      },
      "source": [
        "!pip install --upgrade gensim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_XPCfcIKBxF"
      },
      "source": [
        "To train a word embedding model, you need a large collection of texts. However, we will only use six sentences.\n",
        "We need to tokenize each sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOTyx1fhKLF4",
        "outputId": "17f4cc75-f166-4171-ec87-d0dead30c9c3"
      },
      "source": [
        "\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# define training data\n",
        "texts=[\"Billy always listens to his mother\", \n",
        "       \"He always does what she says\", \n",
        "       \"If his mother says, 'Brush your teeth' Billy brushes his teeth\", \n",
        "       \"If his mother says, 'Go to bed' Billy goes to bed\", \n",
        "       \"Billy is a very good boy\", \n",
        "       \"A good boy listens to his mother\"] \n",
        "\n",
        "sentences=[]\n",
        "for text in texts: \n",
        "    doc = nlp(text)\n",
        "    tokens=[]\n",
        "    for token in doc:\n",
        "        tokens.append(token.text.lower())\n",
        "    sentences.append(tokens)\n",
        "\n",
        "print(sentences)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['billy', 'always', 'listens', 'to', 'his', 'mother'], ['he', 'always', 'does', 'what', 'she', 'says'], ['if', 'his', 'mother', 'says', ',', \"'\", 'brush', 'your', 'teeth', \"'\", 'billy', 'brushes', 'his', 'teeth'], ['if', 'his', 'mother', 'says', ',', \"'\", 'go', 'to', 'bed', \"'\", 'billy', 'goes', 'to', 'bed'], ['billy', 'is', 'a', 'very', 'good', 'boy'], ['a', 'good', 'boy', 'listens', 'to', 'his', 'mother']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1NFZ0MsLmhq",
        "outputId": "4ed1aae7-09d2-4a1b-a620-812365795028"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "# train model\n",
        "#model = Word2Vec(sentences, min_count=2) \n",
        "model = Word2Vec(sentences, vector_size=24, min_count=1, epochs=100)#min_count=2, ignore all words with a frequency < 2\n",
        "word_vectors = model.wv\n",
        "\n",
        "# summarize the loaded model\n",
        "print(model)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word2Vec(vocab=26, vector_size=24, alpha=0.025)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPkBgMFjYa3V"
      },
      "source": [
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def tsne_plot(word_vectors):\n",
        "    \"Create TSNE model and plot it\"\n",
        "    labels = []\n",
        "    tokens = []\n",
        "\n",
        "    words=list(word_vectors.index_to_key)\n",
        "    for word in words:\n",
        "        tokens.append(word_vectors[word])\n",
        "        labels.append(word)\n",
        "    \n",
        "    tsne_model = TSNE(perplexity=40, n_components=2, init='pca', n_iter=2500, random_state=23)\n",
        "    new_values = tsne_model.fit_transform(tokens)\n",
        "\n",
        "    x = []\n",
        "    y = []\n",
        "    for value in new_values:\n",
        "        x.append(value[0])\n",
        "        y.append(value[1])\n",
        "        \n",
        "    plt.figure(figsize=(18, 18)) \n",
        "    for i in range(len(x)):\n",
        "        plt.scatter(x[i],y[i])\n",
        "        plt.annotate(labels[i],\n",
        "                     xy=(x[i], y[i]),\n",
        "                     xytext=(5, 2),\n",
        "                     textcoords='offset points',\n",
        "                     ha='right',\n",
        "                     va='bottom')\n",
        "    plt.show()\n",
        "   \n",
        "tsne_plot(word_vectors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLVIRR5jNaxR"
      },
      "source": [
        "You can save the model. You can also load a pre-trained model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phi3HfcbNaGk",
        "outputId": "d4c18a87-2492-4320-db1c-64f417d289a9"
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "word_vectors.save('model.bin')\n",
        "word_vectors = KeyedVectors.load('model.bin')\n",
        "print(word_vectors['mother'])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-0.03822963 -0.02907381  0.00700192  0.03238377 -0.03816118  0.00777928\n",
            "  0.02326186  0.02347753  0.03438852 -0.03371694  0.01513285  0.02930788\n",
            " -0.01330153 -0.02606933 -0.00156342 -0.04040303 -0.03330088  0.03242779\n",
            "  0.01040922  0.03531139  0.03181361  0.03406015 -0.00531471 -0.00354816]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzL0-OLlPNQP",
        "outputId": "5c9e92be-3a44-4338-c025-94ee48c43be2"
      },
      "source": [
        "similarity = word_vectors.similarity('mother', 'teeth')\n",
        "print(similarity)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.21069106\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xn7IPJQkPcE9",
        "outputId": "f191391c-acf9-4d2b-f354-5df562259440"
      },
      "source": [
        "similarity = word_vectors.similarity('brush', 'brushes')\n",
        "print(similarity)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.015507179\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ku6NHQvcP1Ed"
      },
      "source": [
        "## How to use a pre-trained word embedding model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpTYY4SrP4O8",
        "outputId": "3a2e6068-bece-4245-b98a-c529302d1a3a"
      },
      "source": [
        "import gensim.downloader as api\n",
        "word_vectors = api.load(\"glove-wiki-gigaword-100\")  # load pre-trained word-vectors from gensim-data\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 128.1/128.1MB downloaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVr-IPpnQHvo",
        "outputId": "0d8a9ee1-c726-4d45-89a5-3e79cc1afb43"
      },
      "source": [
        "vector = word_vectors['mother']  # numpy vector of a word\n",
        "print(vector.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvIIWPnMVTU7",
        "outputId": "9826f8ad-ca5e-4cf4-e81b-b6a4eeb5d4eb"
      },
      "source": [
        "word_vectors.most_similar('aspirin')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('ibuprofen', 0.8141189217567444),\n",
              " ('tamoxifen', 0.7157070636749268),\n",
              " ('pills', 0.7089155316352844),\n",
              " ('statins', 0.6964315176010132),\n",
              " ('medication', 0.6923385262489319),\n",
              " ('nsaids', 0.6912236213684082),\n",
              " ('medications', 0.6864854693412781),\n",
              " ('pill', 0.6833402514457703),\n",
              " ('antidepressants', 0.6831307411193848),\n",
              " ('acetaminophen', 0.6780716776847839)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmWTD3jxVgH7",
        "outputId": "7d648e32-6b99-464a-b468-32bf4d6e1267"
      },
      "source": [
        "word_vectors.most_similar('coronavirus')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('coronaviruses', 0.5618978142738342),\n",
              " ('pterosaur', 0.5322613716125488),\n",
              " ('norovirus', 0.5284952521324158),\n",
              " ('sars', 0.5270360112190247),\n",
              " ('prions', 0.5089951157569885),\n",
              " ('vcjd', 0.5069026350975037),\n",
              " ('hiv-1', 0.49967360496520996),\n",
              " ('h9n2', 0.4788110852241516),\n",
              " ('h5n1', 0.47352954745292664),\n",
              " ('prion', 0.47268733382225037)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVoiUSGAQaHz",
        "outputId": "6c105d23-161f-429e-89c6-90fa53cb6de6"
      },
      "source": [
        "result = word_vectors.similar_by_word(\"mother\") #cat\n",
        "for r in result:\n",
        "    print(r)\n",
        "\n",
        "#most_similar_key, similarity = result[0]  # look at the first match\n",
        "#print(f\"{most_similar_key}: {similarity:.4f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('daughter', 0.9063109755516052)\n",
            "('wife', 0.9025879502296448)\n",
            "('grandmother', 0.8934443593025208)\n",
            "('father', 0.8656660318374634)\n",
            "('sister', 0.8647424578666687)\n",
            "('husband', 0.8470974564552307)\n",
            "('woman', 0.827568769454956)\n",
            "('her', 0.8250683546066284)\n",
            "('aunt', 0.8055843114852905)\n",
            "('daughters', 0.7969927191734314)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwZmM9z0Qu50",
        "outputId": "6bbfe4f6-51e0-492b-df63-a38ffcf87b81"
      },
      "source": [
        "w1=\"media\"\n",
        "distance = word_vectors.distance(w1, w1)\n",
        "print(f\"{distance:.1f}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzLpuG95SFms",
        "outputId": "d482b7a4-1114-4c83-d77c-3f91af54d745"
      },
      "source": [
        "distance = word_vectors.distance(\"woman\", \"man\")\n",
        "similarity = word_vectors.similarity('woman', 'man')\n",
        "print(f\"{distance:.1f}\",f\"{similarity:.1f}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.2 0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fk3YRaLUSIse",
        "outputId": "0c745469-8657-4be7-e323-4bd0354531b1"
      },
      "source": [
        "distance = word_vectors.distance(\"woman\", \"house\")\n",
        "similarity = word_vectors.similarity('woman', 'house')\n",
        "print(f\"{distance:.1f}\",f\"{similarity:.1f}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5 0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-D2l9hEWSaAG",
        "outputId": "3ae83a88-f3e4-451c-f206-d28387bc958f"
      },
      "source": [
        "distance = word_vectors.distance(\"woman\", \"wife\")\n",
        "similarity = word_vectors.similarity('woman', 'wife')\n",
        "print(f\"{distance:.1f}\",f\"{similarity:.1f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.2 0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yiZF8LmSemt",
        "outputId": "345ebfc1-2bc0-4f38-f748-f93c8648810b"
      },
      "source": [
        "distance = word_vectors.distance(\"man\", \"husband\")\n",
        "similarity = word_vectors.similarity('man', 'husband')\n",
        "print(f\"{distance:.1f}\",f\"{similarity:.1f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.3 0.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVA64kHaSMiY",
        "outputId": "737aa004-8165-44eb-c580-65c06e8e126f"
      },
      "source": [
        "distance = word_vectors.distance(\"man\", \"cosine\")\n",
        "similarity = word_vectors.similarity('man', 'cosine')\n",
        "print(f\"{distance:.1f}\",f\"{similarity:.1f}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.1 -0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Td0nKnS6P95m"
      },
      "source": [
        "# Check the \"most similar words\", using the default \"cosine similarity\" measure.\n",
        "result = word_vectors.most_similar(positive=['woman', 'king'], negative=['man'])\n",
        "most_similar_key, similarity = result[0]  # look at the first match\n",
        "print(f\"{most_similar_key}: {similarity:.4f}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUn9esFiTaHU",
        "outputId": "b0bbced0-43d0-46bc-a72d-68fbae941f4b"
      },
      "source": [
        "text1 = 'The hotel was very expensive and not good'.lower().split()\n",
        "text2 = 'The hotel was very good and not expensive'.lower().split()\n",
        "text3 = 'The best result was achieved by BERT'.lower().split()\n",
        "\n",
        "distance = word_vectors.wmdistance(text1, text2)\n",
        "print(f\"{distance:.4f}\")\n",
        "\n",
        "distance = word_vectors.wmdistance(text1, text3)\n",
        "print(f\"{distance:.4f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0000\n",
            "0.6942\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olvlq1fuSvJe",
        "outputId": "98e136d3-0680-4e5d-bac8-30f234d5389d"
      },
      "source": [
        "sentence_obama = 'Obama speaks to the media in Illinois'.lower().split()\n",
        "sentence_president = 'The president greets the press in Chicago'.lower().split()\n",
        "sentence_president3 = 'The president greets the media in Illinois'.lower().split()\n",
        "\n",
        "distance = word_vectors.wmdistance(sentence_obama, sentence_president)\n",
        "print(f\"{distance:.4f}\")\n",
        "\n",
        "distance = word_vectors.wmdistance(sentence_obama, sentence_president3)\n",
        "print(f\"{distance:.4f}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6182\n",
            "0.3908\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfkfHNxFT0iN",
        "outputId": "4fe31798-c201-4ec7-ab87-981d1f016614"
      },
      "source": [
        "similarity = word_vectors.n_similarity(['sushi', 'shop'], ['japanese', 'restaurant'])\n",
        "print(f\"{similarity:.4f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7067\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-JJV7QJT3TO",
        "outputId": "533a4c2a-903b-4057-e4fe-0b7541f469bd"
      },
      "source": [
        "similarity = word_vectors.n_similarity(['blue', 'red'], ['japanese', 'restaurant'])\n",
        "print(f\"{similarity:.4f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.4352\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPeWROHTT89U",
        "outputId": "9e0d594c-31c8-4488-b650-960b7747596b"
      },
      "source": [
        "similarity = word_vectors.n_similarity(['sushi', 'red'], ['blue', 'restaurant'])\n",
        "print(f\"{similarity:.4f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8065\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRmZQRKtUGCH",
        "outputId": "bd1609f8-8d7c-42b2-eebd-13101b86ccf2"
      },
      "source": [
        "print(word_vectors.doesnt_match(\"breakfast cereal dinner lunch\".split()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cereal\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WYb_ZgeUHuw",
        "outputId": "b4d17b91-bb75-4af8-a48d-ae7094796b75"
      },
      "source": [
        "print(word_vectors.doesnt_match(\"car ship woman train\".split()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "woman\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDWvm-4aQDv3",
        "outputId": "a45d05b6-231d-4985-8406-60141f7b4159"
      },
      "source": [
        "# Use a different similarity measure: \"cosmul\".\n",
        "result = word_vectors.most_similar_cosmul(positive=['woman', 'king'], negative=['man'])\n",
        "most_similar_key, similarity = result[0]  # look at the first match\n",
        "print(f\"{most_similar_key}: {similarity:.4f}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "queen: 0.8965\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1NO4DZXUfNC",
        "outputId": "9f0a88c7-bd7c-4323-e427-16eb7103dd39"
      },
      "source": [
        "result = word_vectors.most_similar_cosmul(positive=['madrid', 'france'], negative=['spain'])\n",
        "most_similar_key, similarity = result[0]  # look at the first match\n",
        "print(f\"{most_similar_key}: {similarity:.4f}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "paris: 0.9525\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfmCph3pU2sh"
      },
      "source": [
        "Find the top-N most similar words, using the multiplicative combination objective proposed by Omer Levy and Yoav Goldberg in [R10], 3CosMu. \n",
        "\n",
        "Positive words still contribute positively towards the similarity, negative words negatively, but with less susceptibility to one large distance dominating the calculation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yZF7P1UUuVH",
        "outputId": "960c718e-910b-4a1a-dbeb-9dd2a4b4f3b4"
      },
      "source": [
        "result = word_vectors.most_similar_cosmul(positive=['baghdad', 'england'], negative=['london'])\n",
        "most_similar_key, similarity = result[0]  # look at the first match\n",
        "print(f\"{most_similar_key}: {similarity:.4f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iraq: 0.8781\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pautUMgxVpRI",
        "outputId": "14e60045-a30f-4994-ca39-c3577bae56f5"
      },
      "source": [
        "result = word_vectors.most_similar_cosmul(positive=['spain', 'barcelona'], negative=['madrid'])\n",
        "most_similar_key, similarity = result[0]  # look at the first match\n",
        "print(f\"{most_similar_key}: {similarity:.4f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "portugal: 0.9031\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jprOfxyXWZar"
      },
      "source": [
        "\n",
        "tsne_plot(word_vectors)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}